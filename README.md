# Рекомендательная система с учётом «холодных» айтемов (Goodreads YA)

Цель: построить user→item рекомендации, устойчивые к присутствию «холодных» книг (нет взаимодействий в train), и валидировать качество одновременно по «тёплым» и «холодным»

## Начало работы

Для запуска проекта выполните следующие шаги:

**1. Клонируйте репозиторий**
```bash
git clone https://github.com/Arishandrina/goodreads-ya-coldstart-recsys.git
cd goodreads-ya-coldstart-recsys
```

**2. Скачайте данные**
Все необходимые данные (исходные, обработанные и артефакты моделей) не хранятся в репозитории. Скачайте архив по ссылке ниже и распакуйте его в корень проекта

- **[Скачать данные с Яндекс.Диска](https://disk.360.yandex.ru/d/44nUcT1VdXRg1w)**

После распаковки структура вашего проекта должна выглядеть так:
```
goodreads-ya-coldstart-recsys/
├── artifacts/          <-- папка из архива
├── data/               <-- папка из архива
├── processed_data/     <-- папка из архива
├── raw_data/           <-- папка из архива
├── baseline.ipynb      <-- файл из репозитория
├── eda.ipynb           <-- файл из репозитория
└── ... и другие файлы кода
```

**3. Установите окружение**
```bash
python -m venv .venv
source .venv/bin/activate  # Для Windows: .venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt
```

**4. Запустите ноутбуки**
Теперь вы можете воспроизвести все шаги, описанные в разделе "Как воспроизвести"

## Структура проекта

### Файлы в репозитории:
- `baseline.ipynb` — минималистичный шаблон и базовые метрики
- `data_splitting.ipynb` — подготовка и временной сплит данных (train/test)
- `eda.ipynb` — EDA и предобработка (формирование `processed_data/*`, `books_preprocessed.pq`)
- `models.ipynb` — обучение/инференс моделей, сводная таблица метрик, сохранение артефактов
- `requirements.txt` — список зависимостей

### Папки с данными (скачиваются отдельно):
- `data/` — parquet-файлы train/test/books
- `processed_data/` — подготовленные данные для обучения/валидации
- `raw_data/` — исходные json.gz (опционально)
- `artifacts/` — сохранённые модели и результаты (см. ниже)

## Как воспроизвести

1) (Опционально) `data_splitting.ipynb` — пересобрать `data/*.pq`, если нужно
2) `eda.ipynb` — выполнить целиком, чтобы получить `processed_data/*` и `books_preprocessed.pq` с `tfidf_features` 
3) `models.ipynb` — выполнить целиком. В конце появятся артефакты в `artifacts/` и таблица метрик

Порядок и параметры в ноутбуках уже выставлены под воспроизводимость на валидации, близкой к тесту по долям вал/«холодных»

## Протокол валидации

- Валидация только по тёплым пользователям (как в тесте)
- Временной сплит; доля валидации по числу взаимодействий jrjkj 21%; доля «холодных» взаимодействий ≈ 5–6%
- Для каждого пользователя `ground_truth` — список его взаимодействий из валидационной части, отсортированный по релевантности
- Считаем метрики по top‑k, где k=10. Уже прочитанные айтемы при подсчёте исключаются

## Метрики

- `NDCG@10` — качество ранжирования (чувствителен к позициям) 
- `Recall@10` — доля релевантов из `ground_truth` в топ‑10 (без учёта порядка)  
- `Coverage` — доля уникальных рекомендованных книг от всего каталога (прокси‑диверсификация)
- `cold_recall@10` — Recall@10 только по холодным релевантам пользователя (находит ли модель новые релевантные книги) 
- `cold_coverage` — доля уникальных холодных книг, появившихся хотя бы в одном списке рекомендаций (широта охвата новинок)
Метрики считаются функциями `evaluate_recommender` и `cold_recall_and_coverage` в `models.ipynb`

## Реализованные подходы

- Статистические/CF: TopPopular, ItemKNN, SVD, ALS, EASE  
- LTR: CatBoostRanker, LightGBM (переранжирование кандидатов)  
- Контент: TF‑IDF профиль, ContentCold  
- Микс warm+cold: квотирование (7 тёплых + 3 холодных)

## Результаты

Ниже представлена итоговая таблица с метриками всех реализованных моделей

| Модель | ndcg@10 | recall@10 | coverage | cold_recall@10 | cold_coverage |
| :--- | :--- | :--- | :--- | :--- | :--- |
| ItemKNN | 0.102 | 0.088 | 0.596 | 0.000 | 0.000 |
| EASE | 0.093 | 0.085 | 0.526 | 0.000 | 0.000 |
| Mixed 7W+3C | 0.088 | 0.070 | 0.596 | 0.003 | 0.524 |
| ALS | 0.079 | 0.067 | 0.035 | 0.000 | 0.029 |
| SVD | 0.073 | 0.063 | 0.036 | 0.000 | 0.000 |
| CatBoost | 0.053 | 0.054 | 0.430 | 0.000 | 0.000 |
| LightGBM | 0.042 | 0.039 | 0.183 | 0.000 | 0.000 |
| TopPopular | 0.039 | 0.045 | 0.000 | 0.000 | 0.000 |
| ContentCold | 0.003 | 0.002 | 0.109 | 0.010 | 0.751 |

- **Ключевые выводы:**
  - **Практический компромисс:** лидеры по общим метрикам (`NDCG@10`, `Recall@10`) — `ItemKNN` и `EASE`. Но они не способны рекомендовать "холодные" айтемы
  - Требования по «холодным» книгам лучше всего выполняются миксером `Mixed 7W+3C` и контентной моделью `ContentCold`, которые показывают ненулевые `cold_recall@10` и высокий `cold_coverage` при умеренной просадке общих метрик

- Итоговая сводная таблица также сохраняется в `artifacts/results_df.csv`
- Графики сравнения метрик строятся в конце ноутбука `models.ipynb`
  
## Сохранённые артефакты (`artifacts/`)

- `results_df.csv` — сводная таблица метрик
- `mappings.pkl` — `user_to_idx`, `item_to_idx` (используются в нескольких моделях)
- EASE: `ease_W.npz`  
- ALS: `als_user_factors.npy`, `als_item_factors.npy`, `als_meta.pkl` (популярность/пулы для хвоста)  
- SVD: `svd_user_factors.npy`, `svd_item_factors.npy`  
- ItemKNN: `itemknn.pkl` (соседи/сходства/популярность/параметры)  
- CatBoost: `catboost.cbm`, `catboost_meta.pkl` (маппинги)  
- LightGBM: `lightgbm.txt`, `lightgbm_meta.pkl`  
- Контентная ветка использует `processed_data/books_preprocessed.pq` с `tfidf_features`

## Как улучшить (кратко)

- Подобрать квоты миксера (6/4, 5/5), улучшить TF‑IDF (bi‑grams, sublinear tf, больше признаков).  
- LTR с ранжирующей целью (LightGBM `lambdarank` / CatBoostRanker), фичи: `score_ease/itemknn/als`, `content_sim`, поп‑сигналы; квота cold в постпроцессе.  
- Тонкий тюнинг EASE/ALS/ItemKNN, ансамбль скорингов, MMR для диверсификации.  
- Дедуп изданий и фильтры по качеству карточек.

## Лицензия и воспроизводимость

- Проект воспроизводим по ноутбукам и зависимостям из `requirements.txt`
- Используйте Python 3.10+ и Jupyter.  
- Исходные данные — Goodreads (YA); тестовая выборка неизменна
